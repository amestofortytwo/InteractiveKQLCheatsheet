[
    {
        "name": "Query for a table",
        "code": [
            [
                "SecurityEvents",
                "The table name and nothing else makes you see the whole table."
            ]
        ],
        "author": "bittib010",
        "category": [
            "table"
        ]
    },
    {
        "name": "Query building blocks",
        "code": [
            [
                "SigninLogs",
                "Choose the table"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "where TimeGenerated > ago(2d)",
                "Filtering"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "summarize cnt = count() by IPAddress",
                "Aggregating data"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "project IPAddress, cnt",
                "Data reduction/specification"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "order by TimeGenerated",
                "Sort data in the output"
            ]
        ],
        "author": "bittib010",
        "category": [
            "where",
            "project",
            "order by",
            "summarize",
            "count()"
        ]
    },
    {
        "name": "Query a table and limit output records",
        "code": [
            [
                "SigninLogs<br>",
                "Query the whole table."
            ],
            [
                "| ",
                "The Pipe! This symbol is called a pipe, and does exactly what it sounds like - it sends data through, the data you instruct the query to work further on gets sent into this line. "
            ],
            [
                "limit",
                "'limit' will reduce the lines of output to 10 lines which makes the query a lot faster. Note that 'limit' and 'take' are interchangeable. They do the same thing."
            ],
            [
                " 10",
                "The number of output records to be shown - choose any number relevant to your intentions. It is recommended to keep a pretty low number if you are trying to gain some insight into the database for triage purposes."
            ]
        ],
        "author": "bittib010",
        "category": [
            "limit",
            "take",
            "sentinel"
        ]
    },
    {
        "name": "Search every table",
        "code": [
            [
                "SigninLogs",
                "Querying the table of interest"
            ],
            [
                "<br>| search 'success'",
                "Now we're scouting for the word 'success' to be in each output record."
            ],
            [
                "<br>| limit 10",
                "'limit' will reduce the lines of output to 10 records. Note that 'limit' and 'take' are interchangeable. They do the same thing."
            ]
        ],
        "category": [
            "limit",
            "search",
            "take",
            "sentinel",
            "beginner"
        ]
    },
    {
        "name": "Search case sensitive",
        "code": [
            [
                "SigninLogs<br>",
                "Query the whole table."
            ],
            [
                "| search kind = case_sensitive 'OSX'",
                "The search operator is now case sensitive, we've toggled that to 'on' by setting case_sensitive to the 'kind' of search."
            ]
        ],
        "author": "bittib010",
        "category": [
            "case-sensitive",
            "search",
            "kind",
            "sentinel"
        ]
    },
    {
        "name": "Search multiple specific tables",
        "code": [
            [
                "search in (SigninLogs, AzureActivity)",
                "Case-insensitive search through the different tables withing the current database. You choose how many."
            ],
            [
                " 'example@example.com'",
                "The searchword string that you are looking for in those tables."
            ]
        ],
        "author": "bittib010",
        "category": [
            "search",
            "in",
            "sentinel"
        ]
    },
    {
        "name": "Search in multiple tables using wildcard",
        "code": [
            [
                "search in (Device*) 'Windows'",
                "Searches in all the tables that has a name starting with 'Device' and ends with anything. The star is a wildcard, which has a match with everything."
            ]
        ],
        "author": "bittib010",
        "category": [
            "search",
            "wildcard",
            "regex"
        ]
    },
    {
        "name": "Search inside a specific column for a value",
        "code": [
            [
                "SigninLogs<br>",
                "Query the whole table."
            ],
            [
                "| search ",
                "Initialize the searching"
            ],
            [
                "ResultType=='50074'",
                "Set the columnname followed by the keyword you're looking for. The query is now looking for every record where the column ResultType matches '50074' exactly!"
            ]
        ],
        "author": "bittib010",
        "category": [
            "search",
            "sentinel"
        ]
    },
    {
        "name": "search for partial match of a value anywhere in the text in the specified column",
        "code": [
            [
                "SigninLogs<br>",
                "Query the whole table."
            ],
            [
                "| search ",
                "Initialize the searching"
            ],
            [
                "ResultType:'50074'",
                "Set the columnname followed by the keyword you're looking for. The query is now looking for every record where the column ResultType has a partial match with '50074'."
            ]
        ],
        "author": "bittib010",
        "category": [
            "search",
            "sentinel"
        ]
    },
    {
        "name": "Begins with X ends with Y and anything in between",
        "code": [
            [
                "Table<br>",
                "Query the whole table."
            ],
            [
                "| search 'FirstName*LastName'",
                "The star '*' inbetween the two words signalises that between those words, anything goes. A usecase for this query is now to look for a full name in signinlogs, where the middlename could be anything."
            ]
        ],
        "author": "bittib010",
        "category": [
            "search",
            "regex",
            "wildcard",
            "sentinel"
        ]
    },
    {
        "name": "Logical queries with 'search'",
        "code": [
            [
                "SigninLogs<br>",
                "Query the whole table"
            ],
            [
                "| search 'John Doe'",
                "we are now searching for two things to be true - both sides of the 'and' logical statement. 'Name' has to exist in the same record as either or both values in the preceeding 'or' logical statement."
            ],
            [
                " and ",
                "The keyword 'and' is a logical operator that needs both part of the statement to be true for it to proceed with its current data. In a record, 'Name' has to be existing, and whatever comes after has to be evaluated to true."
            ],
            [
                "('50074' or '50126')",
                "At least one of these values inside the braces has to be true to make this exact statement return true. That is how the logical operator 'or' works - by making sure that at least one of the values exists beofre it returns its state. This is not an explicit or. Explicit or returns false if both values exists. "
            ]
        ],
        "author": "bittib010",
        "category": [
            "search",
            "or",
            "and",
            "sentinel"
        ]
    },
    {
        "name": "Search with regex",
        "code": [
            [
                "SigninLogs <br>| search AlternateSignInName",
                "Get your table as usual."
            ],
            [
                " matches regex '[A-Z]'",
                "The syntax for initializing a regex search looks like this. Whatever is inside the quotes (no matter if you use single or double quotes) is the regex. Suggest doing some readup on regex, because regex is really powerfull for looking at patterns!"
            ]
        ],
        "author": "bittib010",
        "category": [
            "regex",
            "matches",
            "sentinel"
        ]
    },
    {
        "name": "Limit the result set with the 'where' clause",
        "code": [
            [
                "SigninLogs<br>| where ",
                "Query the table for a value with the where clause."
            ],
            [
                "TimeGenerated >= ago(2h)",
                "Now we are looking for data WHERE the TimeGenerated is newer or equal to 2 hours ago."
            ]
        ],
        "author": "bittib010",
        "category": [
            "where",
            "ago()",
            "sentinel"
        ]
    },
    {
        "name": "Logical where-clause with AND and OR and brace usage.",
        "code": [
            [
                "SigninLogs<br>| where (Identity == 'Poppy the Goldfish') ",
                "Query the database where table row has value 'Poppy the Goldfish'."
            ],
            [
                "and (TimeGenerated <= ago(2d))",
                "Now we're looking for the second thing basically on the same line"
            ],
            [
                "<br>    and (AppDisplayName == 'Azure Portal' or AppDisplayName == 'Bing')",
                "All sides of these connected 'and' statements needs to be true to get some output. The 'or' inside the braces, one of these has to be true to send a 'true' back to the 'and', because braces have precedence over non-braced statements - they will be evaluated first."
            ]
        ],
        "author": "bittib010",
        "category": [
            "where",
            "and",
            "or",
            "ago()",
            "sentinel"
        ]
    },
    {
        "name": "Simulate 'search' using positional matches",
        "code": [
            [
                "SigninLogs<br>| where * has 'errorCode'",
                "This way you can simulate the search function. It basically says 'Give me everything from SigninLogs where everything has a certain value'."
            ],
            [
                "<br>| where * hasprefix '87.248'",
                "Asks where any(*) columns has the value '87.248' at the beginning"
            ],
            [
                "<br>| where * hassuffix '@outlook.com'",
                "Asks where any(*) column has the value '@gmail.com' at the end."
            ],
            [
                "<br>| where * contains 'OS X 10'",
                "Asks where any(*) column contains the value 'OS X 10' anywhere in its content."
            ]
        ],
        "author": "bittib010",
        "category": [
            "where",
            "hassuffix",
            "hasprefix",
            "contains",
            "search",
            "has",
            "sentinel"
        ]
    },
    {
        "name": "Where-clause with regex - Finding IPv4's",
        "code": [
            [
                "SigninLogs<br>| where Column matches regex '^(?:(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])\\.){3}(?:25[0-5]|2[0-4][0-9]|1[0-9][0-9]|[1-9][0-9]|[0-9])$'",
                "Using this syntax you can leverage the power of regex! Syntax of this query is equal to generating such a query with search instead of where. The regex used here is looking for IPv4 IPs."
            ]
        ],
        "author": "bittib010",
        "category": [
            "where",
            "matches",
            "regex",
            "sentinel"
        ]
    },
    {
        "name": "Count all rows",
        "code": [
            [
                "SigninLogs<br>| count",
                "The count keyword works by counting all of the rows in the current table/input and outputs a number."
            ]
        ],
        "author": "bittib010",
        "category": [
            "count",
            "sentinel"
        ]
    },
    {
        "name": "Count with summarize on specific column(s)",
        "code": [
            [
                "SigninLogs<br>| ",
                "Get the table."
            ],
            [
                "summarize ",
                "Summarize is an aggregated function that lets you work on data and pass it down the pipe. Note that only columns/data you use in summarize are passed on, which means that columns not used are not able to be used after summarize."
            ],
            [
                "count() by ",
                "These keywords tells what you shall count by. Read the whole query like 'From the Table I want to count all the occurences of the Table by ColumnName'"
            ],
            [
                "Identity, Location",
                "Here you choose the column or columns you need to count by. This means that whenever data from this table is equal to one or more, the number will match the number. If you insert multiple columns, all of the values from each columns represent a whole unique 'state', and the state needs to be equal to another to make the counter increment."
            ]
        ],
        "author": "bittib010",
        "category": [
            "summarize",
            "count()",
            "sentinel"
        ]
    },
    {
        "name": "Change name of the count column",
        "code": [
            [
                "Table<br>| summarize myNewColumnName = count() by Column",
                "By including the 'myNewColumnName =' the result from the count() function will be added to a column you decide the name of."
            ]
        ],
        "author": "bittib010",
        "category": [
            "summarize",
            "count()"
        ]
    },
    {
        "name": "Aggregate data with summarize and average (avg).",
        "code": [
            [
                "SigninLogs<br>",
                "Fetching data"
            ],
            [
                "| summarize myNewColumnName = count(), ",
                "Aggregating the data with summarize gives us the possibility to use different aggregation functions like count(), which counts the each occurence of the specified data on the 'by' statement at the end."
            ],
            [
                "myAverageCounterColumn = avg(CounterCol) ",
                "Summarize has also the possibility to calculate the average value of the input with the avg() function."
            ],
            [
                "by Column",
                "This is the column that will determine the outcome. Everything is calculated by this column."
            ]
        ],
        "author": "bittib010",
        "category": [
            "avg()",
            "count()",
            "summarize"
        ]
    },
    {
        "name": "Group timestamps",
        "code": [
            [
                "Table<br>",
                "Fetch the table."
            ],
            [
                "| summarize Column by ",
                "Summarizes data into logical groups based on a timerange. This can also be done with numerical values other than dates. The word bin refers to the data being put into their own matching (timegenerated)bin."
            ],
            [
                "bin(TimeGenerated, 1d)",
                "The bin function takes two parameters, the input timestamp (in this case, bin also works with other numerical values and not just time) and what value to use as a grouping size. Here, everything within 1 day is grouped together."
            ]
        ],
        "author": "bittib010",
        "category": [
            "bin()",
            "summarize"
        ]
    },
    {
        "name": "Add columns - extend",
        "code": [
            [
                "Table<br>| extend calculatedWin = Income * 10.2",
                "Creates a new column based on a value from the current database and multiplies it with 10.2."
            ]
        ],
        "author": "bittib010",
        "category": [
            "extend"
        ]
    },
    {
        "name": "In combination with concatenation, create custom text output",
        "code": [
            [
                "Table<br>| extend calculatedWin = strcat('Current income is', Income')",
                "strcat() makes you able to concatenate strings together, fusing them into a sentence."
            ]
        ],
        "author": "bittib010",
        "category": [
            "strcat()",
            "extend"
        ]
    },
    {
        "name": "Choose columns to pipe further",
        "code": [
            [
                "Table<br>| project",
                "Choose table"
            ],
            [
                "| project",
                "'project' lets you choose which columns you want to move furhter down the KQL pipe."
            ],
            [
                "Column1<br>,Column2<br>Column3",
                "Columns that are chosen to be piped further into the query. Notice the coding style here, which is very helpful when you need to remove an element. It makes it more clean to remove the comma at the same line."
            ]
        ],
        "author": "bittib010",
        "category": [
            "project"
        ]
    },
    {
        "name": "Calculate data with project",
        "code": [
            [
                "Table<br>",
                "Choose table"
            ],
            [
                "| project myCalc = Column1 * 2",
                "Calculates whatever value is in Columns1 with 2 and stores it in column named 'myCalc'."
            ]
        ],
        "author": "bittib010",
        "category": [
            "project"
        ]
    },
    {
        "name": "Remove specific columns from the output with project-away",
        "code": [
            [
                "Table<br>",
                "Choose table."
            ],
            [
                "| project-away ",
                "This function lets you remove columns from the output."
            ],
            [
                "Column1, Column2",
                "These two columns will not show up in the output now."
            ]
        ],
        "author": "bittib010",
        "category": [
            "project-away"
        ]
    },
    {
        "name": "Rename a column with project-rename",
        "code": [
            [
                "Table<br>",
                "Choose table"
            ],
            [
                "| project-rename uniqueName = Column1",
                "Changing the name of Column1 to 'uniqueName'."
            ]
        ],
        "author": "bittib010",
        "category": [
            "project-rename"
        ]
    },
    {
        "name": "Deduplicate output.",
        "code": [
            [
                "Table<br>",
                "Fetch the data."
            ],
            [
                "| distinct ",
                "By piping into the distinct keyword you get to choose what columns you should get unique value combination from."
            ],
            [
                "Column1, Column2",
                "Now, every output row does not contain any duplicates."
            ]
        ],
        "author": "bittib010",
        "category": [
            "distinct"
        ]
    },
    {
        "name": "Output the top X result",
        "code": [
            [
                "Table<br>",
                "Fetch the data."
            ],
            [
                "| top 10 by Column1 asc",
                "Sorts the Column1 ascending and outputs only the 10 from the top. Descending is achieved by 'desc'"
            ]
        ],
        "author": "bittib010",
        "category": [
            "top",
            "asc"
        ]
    },
    {
        "name": "Sorting output",
        "code": [
            [
                "SigninLogs<br>",
                "Choosing table"
            ],
            [
                "sort by",
                "Sorting by any column or columns is possible. By sorting on multiple columns, the further to the left in the columns listing you go the more precedence they will have. This lets you sort output on the current column where the previous columns has duplicate values. Sorting with this keywords defaults to descending for both text and numeric values, and timestamps goes back in time. You can add values 'asc' or 'desc' to change it or make it explicit respectively."
            ],
            [
                "TimeGenerated<br>",
                "Sorts by TimeGenerated and descends back in time."
            ],
            [
                ", ResultType<br>",
                "Every value from 'TimeGenerated' that are duplicates only in that column will now be sorted descending on ResultType."
            ],
            [
                ", ResultDescription asc",
                "Now we're mixing the sorting order up. For every duplicate values of the previous colun (ResultType), ResultDescription will be sorted ascending. You may mix this up as you want by adding 'asc' or 'desc' after your columns listing."
            ]
        ],
        "author": "bittib010",
        "category": [
            "sort by",
            "order by",
            "sentinel"
        ]
    },
    {
        "name": "Extract parts of a string with regex.",
        "code": [
            [
                "SigninLogs<br>",
                "Get the table!"
            ],
            [
                "| project ",
                "Only show the relevant following data, for this query we're working on data extracted with extract()."
            ],
            [
                "extract(\"([a-z]{1,5})\"",
                "The extract scalar function takes three parameters, and the first one being what to search for - here we are using regex. What the regex says is 'any charachter from a to z, lower capital and i want every match with a length of between 1 to 5'."
            ],
            [
                ", 1, ",
                "The second parameter tells 'extract' what to return. '1' means to return only the part of the string that matches. setting it to zero makes it return the whole string where there is a match."
            ],
            [
                "tostring(LocationDetails))",
                "This is the string we are searching through with 'extract', it's the third parameter to the scalar function. Now, since this field in the Sentinel database is not a string, we need to convert it to a string using tostring() and putting the column inside the brackets."
            ]
        ],
        "author": "bittib010",
        "category": [
            "extract()",
            "project",
            "regex",
            "tostring()"
        ]
    },
    {
        "name": "Parse longer texts and store output to column <a target='_blank' href='https://blog.amestofortytwo.com/kusto-detective-agency6/'>Full writeup</a>",
        "code": [
            [
                "ChatLogs",
                "Get the table! This query is taken from a writeup of the Kusto Detective series, see the title of the query dropdown to access a link. Here is an example of text in the field we will be parsing: User 'u71fb5058bd' sent message to the channel 'c72cd0fdf88'"
            ],
            [
                "| parse Message with ",
                "Initializing the 'parse' operator we need to tell it which column we want to parse. In this case, the Message column, 'with' is part of the syntax. Is it here to make it more humanly readable? One could think of parse as a way of telling KQL where to put the cursor to start parsing from."
            ],
            [
                "'User '",
                "First, we need to set the cursor at the right spot. Knowing where to put it takes some knowledge of the data you want to parse. Here, we know that we will read passed the text 'User ', the next character will now be where the cursor is."
            ],
            [
                " user ",
                "This is the variable name to store the text we are parsing, and the text that gets stored is the text between the previous cursor set, to the start of the next cursor set..."
            ],
            [
                "' sent message to the channel '",
                "...which is here. Now we are moving the cursor to the end of the sentence of this and we will parse out whatever is left from the next character. "
            ],
            [
                " sent_to_channel<br>",
                "And then we store that in this variable."
            ],
            [
                "| parse Message with 'User ' user1 ' left the channel ' left_channel<br>",
                "The same procedure here as the first one explained in depth."
            ],
            [
                "| parse Message with 'User ' user2 ' logged out from the ' logged_out_from<br>",
                "The same procedure here as the first one explained in depth."
            ],
            [
                "| parse Message with 'User ' user3 ' joined the channel ' joined_channel<br>",
                "The same procedure here as the first one explained in depth."
            ],
            [
                "| parse Message with 'User ' user4 ' logged in from ' loginIP<br>",
                "The same procedure here as the first one explained in depth."
            ],
            [
                "| parse Message with 'User ' user5 ' sent message to the user ' sent_to_user<br>",
                "The same procedure here as the first one explained in depth."
            ],
            [
                "| extend TheUser = strcat(user, user1, user2, user3, user4, user5) <br>",
                "The same procedure here as the first one explained in depth."
            ],
            [
                "| project-away user, user1, user2, user3, user4, user5",
                "Removed unecessary data with project-away."
            ]
        ],
        "category": [
            "kustodetectiveagency2022",
            "parse",
            "extend",
            "project-away",
            "strcat()",
            "with"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2022 - Onboarding. <a target='_blank' href='https://blog.amestofortytwo.com/kusto-detective-agency1/'>Full writeup</a>",
        "code": [
            [
                "Onboarding<br>| summarize sum(Score)",
                "Basic and simple query to sum up all numeric values in the Score column."
            ]
        ],
        "category": [
            "kustodetectiveagency2022",
            "summarize",
            "sum()"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2022 - Rookie - The rarest book is missing. <a target='_blank' href='https://blog.amestofortytwo.com/kusto-detective-agency2/'>Full writeup</a>",
        "code": [
            [
                "Shelves<br>",
                "Fetching the whole table. "
            ],
            [
                "| mv-expand rf_id = rf_ids to typeof(string) <br>",
                "mv-expand takes the array that is in 'rf_ids' and expands the table records (rows) by adding an entry for each value. This means that the rest of the columns will remain the same for all of the array values, and get the advantage of individually querying them. Each of the element is then converted into a string with typeof(string)."
            ],
            [
                "| lookup Books on rf_id<br>",
                "lookup has a similar effect like join. It combines two tables: Books and rf_id. The type of lookup here is default, meaning leftouter. lookup differs from join by not having repeating columns from the $right table and it assumes that $left table is the larger table. So what we are doing here is, we are looking up all the information from Books and broadcasting it based on rf_id from $right to $left."
            ],
            [
                "| project shelf, author, book_title, total_weight, weight_gram<br>",
                "Projecting these through the pipe to reduce amount of data and make it more accurate towards what we're aiming for."
            ],
            [
                "| summarize bookWeight = sum(weight_gram), claimedWeight = min(total_weight) by shelf<br>",
                "We now know what weight every book weighs and we know the total weight, here we do calculations by each shelf and sums up the weight_gram (the weight of each book) of the shelf. claimed_weight is self-explanatory knowing that there are some values that are slightly off, what makes the accuracy of the weight different."
            ],
            [
                "| extend difference = (claimedWeight - bookWeight)<br>",
                "Working further on the previous calculations we now expect to see some output. Most of the books create differences due to the inaccuracy of the measurement, but if a whole book is missing the value will stand out."
            ],
            [
                "| order by difference desc",
                "Ordering the output descending makes the largest number arise to the top - and thats out goal!"
            ]
        ],
        "category": [
            "kustodetectiveagency2022",
            "mv-expand",
            "typeof()",
            "sum()",
            "min()",
            "summarize",
            "extend",
            "order by",
            "lookup"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2022 - Detective 1 - Election fraud? <a target='_blank' href='https://blog.amestofortytwo.com/kusto-detective-agency3/'>Full writeup</a>",
        "code": [
            [
                "Votes<br>",
                "Fetching the whole table. "
            ],
            [
                "| summarize hits = count() by bin(Timestamp, 5s), via_ip, vote<br>",
                "By summarizing by a timerange of 5 seconds, via_ip and vote we get the value of how many unique entries/votes there are on those columns. The 5 seconds value was figured out by viewing 'by eye' for a pattern on the timestamps, and there was a iterative pattern based on IP addresses every 5 seconds."
            ],
            [
                "| where hits < 2<br>",
                "One could assume that a voting would not take place more than twice in the 5 seconds, from the same ip and for the same candidate. If this is a miss, it will not be a big miss and we might still get to the correct answer as numbers are rounded for the delivery of the task. Less than two is considered to be 'normal' traffic'."
            ],
            [
                "| summarize Count = count() by vote<br>",
                "Next we are counting all of the votes. Note, that summarize only brings on the columns that are being worked on, so only Count and vote are reachable right after this statement."
            ],
            [
                "| as hint.materialized=true ",
                "This part makes you able to store the current dataset you have piped thus far for later retrieval without storing it by using 'let'. The output of this is cached in memory. Also, this acts similar to the function materialize(), which on the other hand often uses the let statement."
            ],
            [
                " T <br>",
                "This is now the variable name of the current state of the query."
            ],
            [
                "| extend Total = toscalar(T <br>| summarize sum(Count))<br>",
                "Now we are adding a new column that will hold the sum of Count - the total Count."
            ],
            [
                "    | project vote, Percentage = round(Count*100.0 / Total, 1), Count<br>",
                "Project is also usefull for calculation, as well as we reduce the amount of data we are sending through the pipeline. This is basic math to get the percentage."
            ],
            [
                "| order by Count",
                "Order by Count - defaults to descending."
            ]
        ],
        "category": [
            "kustodetectiveagency2022",
            "project",
            "extend",
            "hint.materialized",
            "where",
            "summarize",
            "order by",
            "summarize",
            "count()",
            "bin()"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2022 - Detective 2 - Bank Robbery <a target='_blank' href='https://blog.amestofortytwo.com/kusto-detective-agency4/'>Full writeup</a>",
        "code": [
            [
                "let afterRobbery = Traffic<br>",
                "The let statement tells KQL to handle everything that comes after up until a semicolong to be treated and stored as a variable for later retrieval and use. And we are starting out by setting the variable equal to the Traffic."
            ],
            [
                "| where Timestamp between(datetime(2022-10-16 08:31:00) .. datetime(2022-10-16 08:40:00))<br>",
                "Next we are looking for all data that resides in between the given datetimes. The time we are looking at here are the times for when the robbers left the scene and when the police arrived (in other words, when we are sure they have left the scene). The robbers cars has to be between these timedates. But where are they?"
            ],
            [
                "| summarize arg_min(Timestamp, *) by VIN<br>",
                "Summarizing with the arg_min function, we are able to get the cars that left the scene first within our timerange (first parameter). The second parameter inside arg_min is the star, the wildcard, the everything. It is basically where you tell the function what kind of columns you want to bring on through the query - like it's own internal pipe. And least, we summarize by VIN."
            ],
            [
                "| where Ave == 157<br>",
                "And up until now, we have only been looking at a timerange (between()), we know that after 08:31:00 and 08:40:00 the robbers left the Avenue 157 and..."
            ],
            [
                "| where Street == 148<br>",
                "... the street 148. These two last lines could have been combined into a logical 'and'."
            ],
            [
                "| summarize make_list(VIN);<br>",
                "Next up we need to use summarize to store our output into a list so that we could easily retrieve it afterwards. I like the simplicity KQL gives of asking for occurences inside a list. Lastly for this part of the let statement (variable building), we are telling KQL to stop building the variable by a semicolon. So, to sum this variable up, we have now stored every car that was on a certain avenue and street at the beginning of a very interesting timeframe, and we know that the robbers are among the cars. We have reduced our dataset immensely!"
            ],
            [
                "Traffic<br>",
                "Let's use the variable to get the related information of the vehicles of interest on the full dataset."
            ],
            [
                "| summarize arg_max(Timestamp, *) by VIN<br>",
                "Now this is an interesting approach! We know by the text that the cars have stopped, because there aren't any cameras cathing their movement anylonger. Which means that we can look at all the data and see where every car in the whole table was last seen. And we know that there are more than 1 car, they probably had one each, making it 3 cars. arg_max lets us see the latest entry based on Timestamp by VIN. Like arg_min, we're sending through every column."
            ],
            [
                "| where VIN in (afterRobbery)",
                "And now we're reducing the data to match our previous findings and we can see three cars that has stopped on the same avenue and street! Those are the robbers!"
            ]
        ],
        "author": "bittib010",
        "category": [
            "arg_max()",
            "arg_min()",
            "kustodetectiveagency2022",
            "let",
            "make_list()",
            "where",
            "between()",
            "datetime()",
            "summarize"
        ]
    },
    {
        "name": "Kusto Detective Agency 2022 - Detective 2 - Bank Robbery - Rendering a path-map! <a target='_blank' href='https://blog.amestofortytwo.com/kusto-detective-agency4/'>Full writeup</a>",
        "code": [
            [
                "Traffic<br>",
                "Get the whole table."
            ],
            [
                "| where VIN in ('XC2952A7FB', 'RI8E6C4294', 'CXDE148D63')<br>",
                "Reduce the set to all of the known VIN's of the robbers."
            ],
            [
                "| summarize Ave = make_list(Ave), Street = make_list(Street) by VIN<br>",
                "Summarize and make a list to make the colors in the rendering stand out and we're summarizing on the VINs"
            ],
            [
                "| render scatterchart",
                "This is rendering a scatterchart for vizualisation of data and for this task it proves to be really interesting, because it shows the exact path each driver has made before arriving at the hiding spot."
            ]
        ],
        "author": "bittib010",
        "category": [
            "render",
            "scatterchart",
            "summarize",
            "make_list()",
            "in",
            "where"
        ]
    },
    {
        "name": "Kusto Detective Agency 2022 - Detective 3 - Ready to play? - Prime numbers <a target='_blank' href='https://blog.amestofortytwo.com/kusto-detective-agency5/'>Full writeup</a>",
        "code": [
            [
                "Primes<br>",
                "Fetching the whole Primes table which contains a lot of prime numbers for use in this task. "
            ],
            [
                "| serialize <br>",
                "As we know, we need to make the one row of primes able to add to it's own neighbour and then plus 1. We therefore need to order the table, for that we use serialize to make it able to apply window functions. Window functions operate on multiple rows at a time. A window is basically a set of rows to work with at the same time, instead of only one row at a time."
            ],
            [
                "| join Primes on Prime<br>",
                "Next up, we need to join the table with itself, on the same (and only) column."
            ],
            [
                "     | serialize<br>",
                "This has to be serialized also!"
            ],
            [
                "    | extend nextPrime = next(Prime)<br>",
                "Next up, and this might be a good answer as to why the order matters - we add (extend) another column where we look ahead at the next() value and outputs that. Remember that we need the neighboring prime number. next() is considered a window function - it works on multiple rows at a time. Other such functions are prev(), row_cumsum(), row_number(), row_rank_dense(), row_rank_min(), row_window_session()."
            ],
            [
                "| extend result = nextPrime + Prime + 1<br>",
                "And then we do our calculations. Prime + next() prime + 1."
            ],
            [
                "| join kind=inner Primes on $left.result == $right.Prime<br>",
                "Part of the equation was that a special prime was calculated like above, but also resulted in a prime - and as we have a huge list of primes, we can check against it by joining the columns. This is simple syntax that chooses the kind of join to be inner. In a lot of languages, inner is the default, but with KQL innerunique is the default - therefore we need to specify inner. Joining these two columns and returning with a result only if they match is basically the explanation to 'inner'."
            ],
            [
                "| summarize maxPri = max(result)<br>",
                "We we're tasked with finding the highest number available - max() does the job for us. Another approach would be to sort the output and piping it into take/limit 1. "
            ],
            [
                "| project TheAnswer=strcat(\"https://aka.ms/\", maxPri)<br>",
                "The task was to enter into a page with this given string as preceeding the number we found - lets concatenate those with strcat(). strcat() takes two parameters, the first and second strings you want to concatenade - fuse together."
            ]
        ],
        "category": [
            "summarize",
            "max()",
            "strcat()",
            "join",
            "kind",
            "inner",
            "serialize",
            "project",
            "extend",
            "next()"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2022 - Detective 3 - Ready to play? Mapping trees.<a target='_blank' href='https://blog.amestofortytwo.com/kusto-detective-agency5/'>Full writeup</a>",
        "code": [
            [
                "let h3Tree = nyc_trees<br>",
                "Starting by creating a variable and calling the nyc_trees table."
            ],
            [
                "| extend  h3Cell=geo_point_to_h3cell(longitude, latitude, 10);<br>",
                "H3cells is a spatial grid system for geo location where the grids basically consist of hexagons. Hexagons share the same distance to all of its closest neighbours and they have the highest number of neighbours if you were to calculate only neighbours where there is an edge-share. Subdivision is also key, where squares are able to subdivide perfectly, hexagons are not. But the system Uber made, subdivide one hexagon into 7 and rotate them slightly. This way they are able to map out large areas in only a handfull of hexagons and also to make the shapes fit into most kind of lansdscape shapes. parameters are longitude, latitude and cellsize (10 aprox 66m)."
            ],
            [
                "let cells = h3Tree| where spc_common has_any ('Schubert', 'Turkish', 'American')<br>",
                "Next we're making a new variable that will store all the important treetypes within the given radius we need (based on h3cell system)."
            ],
            [
                "| project h3Cell, spc_common<br>",
                "Let's bring forward only the parts we need to work with."
            ],
            [
                "| evaluate pivot(spc_common): (h3Cell:string , [\"'Schubert' chokecherry\"]:int, ['Turkish hazelnut']:int, ['American linden']:int)<br>",
                "This is a very interesting and powerfull function. Microsoft has this explanation: pivot() rotates a table by turning the unique values from one column in the input table into multiple columns in the output table and performs aggregations as required on any remaining column values that will appear in the final output.. Which means that for every species we will add a new column and add the data count the matches residing in the same h3Cell - 66 meter radius."
            ],
            [
                "| where [\"'Schubert' chokecherry\"] == 4 and ['Turkish hazelnut'] > 0 and ['American linden'] > 0;<br>",
                "The last part pivoted the data around and counter occurences of trees within the given h3cell, now we are looking up that info to see where it matches our task. And then we're closing the let statement with a semicolon."
            ],
            [
                "h3Tree<br>",
                "Calling the variable h3Tree."
            ],
            [
                "| join kind=inner cells on h3Cell<br>",
                "And now we're doing an inner join on the other variabel(table) we created 'cells' on h3Cell. "
            ],
            [
                "| where spc_common == 'American linden'<br>",
                ".. and then we want to see if we can find any of the listed word/names inside 'spc_common'. This reduces our dataset."
            ],
            [
                "| summarize arg_min(tree_dbh, *)<br>",
                "Let's find the tree with smallest diameter."
            ],
            [
                "| project latitude, longitude<br>",
                "We only want lat and long to find out where we want to go."
            ]
        ],
        "category": [
            "h3Cell",
            "evaluate",
            "pivot()",
            "geo_point_to_h3cell()",
            "project",
            "summarize",
            "where",
            "join",
            "inner",
            "arg_min()",
            "kind",
            "inner",
            "where",
            "and",
            "has_any"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2022 - Senior Detective - Big Heist <a target='_blank' href='https://blog.amestofortytwo.com/kusto-detective-agency6/'>Full writeup</a>",
        "code": [
            [
                "let logs = ChatLogs<br>",
                "Let's start by making a variable."
            ],
            [
                "| extend user = tostring(split(Message, \"'\")[1]), target = tostring(split(Message, \"'\")[3])<br>",
                "By taking a look at the data we have available it's pretty evident that each value has been split up in such a way that we can divide the data and extend it into its own column. Let's split the data on every '. This makes it into a list and then we can use the wanted index is using square brackets. Usernames are at position 1 and target is at position 3 after it has been split on each '."
            ],
            [
                "| extend activity = extract(@\"(joined|left|user|channel|logged in|logged out)\", 1, Message);<br>",
                "This line contains regex. extract() uses regex to retrieve matching input to give output from. Here we are looking for line that contains any of the words, and they are separated by a line, a pipe which means 'or'. joined or left or user or..."
            ],
            [
                "let joiners = logs<br>",
                "Let's make our first assumption. Based on the data we have been delivered we have people joining, leaving, logging in/out etc. What this tells me is that the gang-members might have a policy on how long they are allowed to stay online, or that they need to log in and out each time, join/leave… Therefore, we need to make a list of joins."
            ],
            [
                "| where activity == \"joined\"<br>",
                "Looking for activity is 'joined'."
            ],
            [
                "| summarize ts = dcount(tostring(user)) by bin(Timestamp, 1m), target<br>",
                "We know that we are looking for a gang existing of 4 members, therefore we have to count distinct joiners on a short timegap (bin) based on target."
            ],
            [
                "| where ts == 4<br>",
                "The gang has 4 members."
            ],
            [
                "| distinct target<br>",
                "We don't want duplicates."
            ],
            [
                "| summarize make_list(target);<br>",
                "Let's make targets into a list."
            ],
            [
                "let crimChannel = logs<br>| summarize c = dcount(user) by target<br>| where c == 4 and target in (joiners)<br>| summarize make_list(target);<br>",
                "Here we are counting distinct users by target, filtering out channels with only 4 members and where they are part of the list in joiners, before making it into a list."
            ],
            [
                "let crimUsers = logs<br>| where target in (crimChannel)<br>| distinct user<br>| summarize make_list(user);<br>",
                "Here we are using the output of the previous to find the users who belongs to a channel. These users are currently the most suspected persons we know of, but we need to confirm our belief."
            ],
            [
                "logs<br>| where activity == \"logged in\" and user in (crimUsers)<br>| distinct target<br>| project strcat(\"https://sneakinto.z13.web.core.windows.net/\", target)",
                "At last we will look at all the data where our suspected users have logged into."
            ]
        ],
        "category": [
            "distinct",
            "let",
            "summarize",
            "extend",
            "project",
            "where",
            "strcat()",
            "make_list()",
            "in",
            "dcount()",
            "bin()",
            "extract()",
            "tostring()",
            "split()",
            "where"
        ],
        "author": "bittib010"
    },
    {
        "name": "Filter records from a table",
        "code": [
            [
                "MyTable | where Field1 == 'value1'",
                "Filter records from MyTable where Field1 is equal to 'value1'. 'filter' is the same as 'where' in KQL."
            ]
        ],
        "category": [
            "where",
            "filter"
        ],
        "author": "remiks"
    },
    {
        "name": "Summarize data from a table",
        "code": [
            [
                "MyTable | summarize count() by Field1",
                "Count the number of records in MyTable for each unique value of Field1"
            ]
        ],
        "category": [
            "summarize",
            "count()"
        ],
        "author": "remiks"
    },
    {
        "name": "Join data from two tables",
        "code": [
            [
                "Table1 | join kind=inner Table2 on Field1",
                "Join records from Table1 and Table2 where Field1 matches"
            ]
        ],
        "category": [
            "join",
            "inner",
            "kind"
        ],
        "author": "remiks"
    },
    {
        "name": "Extract fields from a table",
        "code": [
            [
                "MyTable | project Field1, Field2",
                "Select only Field1 and Field2 from MyTable"
            ]
        ],
        "category": [
            "project"
        ],
        "author": "remiks"
    },
    {
        "name": "Onenote execution (embedded file abuse) <a target='_blank' href='https://blog.nvisio.eu/2023/02/27/onenote-embedded-file-abuse/'>Source </a>",
        "code": [
            [
                "union DeviceProcessEvents, DeviceFileEvents",
                "These two tables will be combined into the same output - no deduplication happens - everything spits out."
            ],
            [
                "<br>| where ProcessCommandLine",
                "Lets start with this column and then check to see if it contains whatever we specify next."
            ],
            [
                " matches regex",
                "These keywords are used to initiate a regex search. Sentinel uses RE2 regex engine."
            ],
            [
                "@\"",
                "... which also has to start with the @ symbol to treat it like regex."
            ],
            [
                ".",
                "A simple punctuation means that the value of this exact spot is set to be any character. "
            ],
            [
                "*",
                "The star * tells the regex enginve to treat the punctuation (or any other preceding operator)operator to be repeated. The start means to repeat it zero or more. These types of operators are called repetition operators and there are two others: + (one or more) and ? (zero or one). Translated into the query this means that whatever comes before C:\\\\ is anything in length as long as they are character (or to say, until anything else is met which is not a character)."
            ],
            [
                "C:\\\\Users\\\\.*\\\\AppData\\\\Local\\\\Temp\\\\OneNote\\\\.*\\\\Exported\\\\.*\"",
                "And as you can see, this is being repeated a few times inside this string. "
            ],
            [
                " or ",
                "Logical operator. This tells to see for another match. When KQL reads a row it checks for both matches, at least one of them has to match to be sent further through any pipe or printed."
            ],
            [
                "FolderPath matches regex @\".*C:\\\\Users\\\\.*\\\\AppData\\\\Local\\\\Temp\\\\OneNote\\\\.*\\\\Exported\\\\.*\"",
                "Everything is repeated once more for the other column of interest."
            ]
        ],
        "category": [
            "sentinel",
            "union",
            "regex",
            "matches",
            "or",
            "where"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2023 - Onboarding - Method 1",
        "code": [
            [
                "DetectiveCases<br>",
                "Get the whole table."
            ],
            [
                "| summarize count() by DetectiveId<br>",
                "Count all the cases each Detective has, this might indicate who earned the most. This would not yield an accurate answer if the one who has completed most cases also was one that earned the least for each case. A little luck here."
            ],
            [
                "| where DetectiveId != ''<br>",
                "Some results was blank, avoid these. You could also use the isnotempty() function. "
            ],
            [
                "| top 1 by count_",
                "The top keyword lets you organize the output in a given manner (<b>asc</b>ending or <b>desc</b>ending), where desc (highest number first) is the default. As we did not call our count() calculation anything, it defaults to a name of 'count_'. top 1, means to return only the top one in a descending order."
            ]
        ],
        "category": [
            "beginner",
            "summarize",
            "top",
            "count()"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2023 - Onboarding - Method 2",
        "code": [
            [
                "let Bounties = DetectiveCases<br>",
                "Starting a bit more advanced approach, which is also precise in comparison to the first approach. We start out by creating variables which we will use later. As the data set of this table is a mixup and duplicates, it does not state who has won the bounty. Therefore, we need to calculate that. We start of by finding all the entries that has "
            ],
            [
                "| extend Bounty = toint(Properties.Bounty)<br>",
                "The 'Properties' column, contains json values, and we can easily extract the value from it that we want by using dot-notation. The values we need are inside the 'Bounty' key. This needs to be wrapped into the toint() function to make it into an integer so that we can do maths on it."
            ],
            [
                "| where isnotempty(Bounty)",
                "This line only removes those lines with no Bounties. As mentioned, the data set is a mix of different stages of a bounty hunter from information on bounties available, completed cases, started and so on. This line is not necessary for the end result, but it made the query go faster. It is also worth mentioning that good hygiene in KQL is to put where-clauses as early as possible to reduce the dataset early. Adding this line made the whole query on avergae (calculated by 10 runs) aproximately 7 times faster."
            ],
            [
                "| project CaseId, Bounty;<br>",
                "For this variable we are only interested in the bounties and the cases the bounties will be or have been payed out for."
            ],
            [
                "let firstSolvedBy = DetectiveCases<br>",
                "After some initial pattern orientation on the dataset, it seemed natural to think that multiple detectives may have started an investigation, yet only one would be payed. Let's create a variable holding those detectives that first solved a case."
            ],
            [
                "| where EventType == 'CaseSolved'<br>",
                "Filtering on only cases that were solved."
            ],
            [
                "| summarize arg_min(Timestamp, DetectiveId) by CaseId;<br>",
                "arg_min() works in such a way that it finds the earliest (if timestamp) or the lowest/minimum of the first argument given, based on the second argument - DetectiveId. And since we are looking at cases solved, this translated into The first detective that has solved a case."
            ],
            [
                "DetectiveCases<br>",
                "Load the table once more."
            ],
            [
                "| join kind=inner firstSolvedBy on CaseId<br>",
                "Next, we'll combine the initial solvers based on the CaseId. Consequently, certain columns will have duplicate entries. However, KQL handles this situation by appending an iterated number to the duplicates, corresponding to the total number of duplicates. For example, if there are two duplicates of DetectiveId, the second one will be labeled as DetectiveId1, and so forth."
            ],
            [
                "| join kind=inner Bounties on CaseId<br>",
                "The same as for the previous line, we now have two more columns: CaseId2 and Bounties. Now they align with the correct detective and case ID. "
            ],
            [
                "| summarize sum(Bounty) by DetectiveId1<br>",
                "Let's sum() up the number of bounties by each DetectiveID to figure out who ACTUALLY earned the most."
            ],
            [
                "| top 1 by sum_Bounty<br>",
                "Tune it down to the one and only Detective. The winner!"
            ]
        ],
        "category": [
            "join",
            "let",
            "summarize",
            "top",
            "sum()",
            "arg_min()",
            "project",
            "where",
            "extend"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2023 - Case 1 - To bill or not to bill? - Method 1",
        "code": [
            [
                "Consumption<br>",
                "This first method is the method that made most sense to me. I is based on getting back all the positive, or the highest numbers, and uses those to calculate. Because the dataset is filled with duplicates, but a negative number."
            ],
            [
                "| summarize max_consumed = max(Consumed) by bin(Timestamp, 1d), MeterType, HouseholdId<br>",
                "Let's take a look at the Households based on timestamps and MeterType where we focus on the max consumed for everyday (therefore bin() by 1d). By looking for patterns on the dataset to figure out how to attack this challenge it became evident pretty early that each Household had more than one entry on the same metertype a day. We want to stick to one. Also a weird find was that there was a lot of negative entries."
            ],
            [
                "| summarize TotalConsumed = sum(max_consumed) by MeterType<br>",
                "Lets sum() up the max_consumed for each MeterType. This will make us see what each house will be billed for each metertype."
            ],
            [
                "| lookup Costs on MeterType<br>",
                "lookup is pretty similar to join, it joins a table on a given column. Here, we are looking up the Costs table on it self (since we are already working in that table) based on Metertype which we currently need to separate as they need to be calculated separately based on differing prices."
            ],
            [
                "| extend TotalCost = TotalConsumed*Cost<br>",
                "Now, let's do the calculation."
            ],
            [
                "| summarize sum(TotalCost)",
                "And then sum() it up!"
            ]
        ],
        "category": [
            "sum()",
            "extend",
            "lookup",
            "summarize",
            "max()",
            "bin()"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2023 - Case 1 - To bill or not to bill? - Method 2",
        "code": [
            [
                "Consumption<br>",
                "This second method only has a fractional difference compared to method 1. Is this why they accept answers within a range?"
            ],
            [
                "| distinct Timestamp, HouseholdId, MeterType, Consumed<br>",
                "Let's take a look at the Households based on timestamps and MeterType where we focus on the max consumed for everyday (therefore bin() by 1d). By looking for patterns on the dataset to figure out how to attack this challenge it became evident pretty early that each Household had more than one entry on the same metertype a day. We want to stick to one. Also a weird find was that there was a lot of negative entries."
            ],
            [
                "| summarize TotalConsumed = sum(Consumed) by MeterType<br>",
                "Lets summarize up the Consumed for each MeterType. This will make us see what each house will be billed for each metertype."
            ],
            [
                "| lookup Costs on MeterType<br>",
                "lookup is pretty similar to join, it joins a table on a given column. Here, we are looking up the Costs table on it self (since we are already working in that table) based on Metertype which we currently need to separate as they need to be calculated separately based on differing prices."
            ],
            [
                "| extend TotalCost = TotalConsumed*Cost<br>",
                "Now, let's do the calculation."
            ],
            [
                "| summarize sum(TotalCost)",
                "And then sum() it up!"
            ]
        ],
        "category": [
            "sum()",
            "extend",
            "lookup",
            "summarize",
            "distinct"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2023 - Case 1 - To bill or not to bill? - Data pattern exploration",
        "code": [
            [
                "Consumption<br>",
                "Load the data. This query I made after realizing that there were negative numbers affecting the outcome, so I wanted to test if this happened on a special day that I could use as some kind of pivot point. What I realized was that it contained the "
            ],
            [
                "| summarize max(Consumed), min(Consumed) by bin(Timestamp,1d), MeterType<br>",
                "Prepare the data by aggregating it into what you'd like to output. What we are interested in, is to generate data that shows the difference between the highest and lowest numbers. This query makes it clear that somethings happened at the 7th of April. Move on to the next query to see if we can verify this."
            ],
            [
                "| render timechart with(anomalycolumns=min_Consumed,max_Consumed)<br>",
                "This syntax renders the a timechart that shows exaclty what we need. This query is however not fulfilling all questions. We are still wondering if there are any data left inbetween these values per Household and MeterType. Because we are only looking at min() and max(). Lets jump to the next query to see if we need to take this further."
            ]
        ],
        "category": [
            "sum()",
            "extent",
            "lookup",
            "summarize",
            "anomalycolumns",
            "render",
            "timechart",
            "with",
            "max()",
            "min()",
            "bin()"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2023 - Case 1 - To bill or not to bill? - Data pattern exploration 1",
        "code": [
            [
                "Consumption<br>",
                "Load the data."
            ],
            [
                "| summarize count() by bin(Timestamp, 1d), HouseholdId, MeterType<br>",
                "Count every instance of Costs-entry for each day per household and Metertype. That's a mouthfull. When you dont name your count() aggregation, KQL automatically names it 'count_'."
            ],
            [
                "| where count_ > 1<br>",
                "We are expecting 1 to be the normal entry per day for each metertype and household. If there are any more, this should be treated as out of the ordinary. We are looking to confirm if there are a maximum of two or if some houses have more than two entries."
            ],
            [
                "| order by Timestamp desc<br>",
                "Running the query, it seems like we are left with maximum of two. This means that we can easily use max() in our final query to filter out the noise. Also, note the date 7th of April. Something happened that day. Thats the first day of two entries per household and metertype."
            ]
        ],
        "category": [
            "order by",
            "where",
            "count_",
            "summarize",
            "bin()",
            "count()"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2023 - Case 2 - Catch the Phishermen",
        "code": [
            [
                "let called = PhoneCalls<br>| where EventType == 'Connect'<br>| project Connect_Time = Timestamp, CallConnectionId;<br>",
                "For this challenge we have to make some kind of assumption. My assumption came to me after sifting through the data looking for patterns. I could not find any. And it led me to think into what we are looking at and what is the crime being committed. Let's assume that the phishermen had among the longest lasting calls. Let's start by creating a variable that stores both when every call started and the related CallConnectionId."
            ],
            [
                "let disc = PhoneCalls<br>| where EventType == 'Disconnect'<br>| project Disconnect_Time = Timestamp, CallConnectionId;<br>",
                "Now, let's do the same for disconnected calls based on CallConnectionId."
            ],
            [
                "let duration = called<br>",
                "| join disc on CallConnectionId<br>",
                "We now have to combine these two variables to calculate the duration of each call. We are joining on CallConnectionId as these are unique to each call made."
            ],
            [
                "| extend call_duration = datetime_diff('second',Disconnect_Time, Connect_Time);<br>",
                "Adding a column for our calculation using datetime_diff. And we want to return the resulting difference or duration in seconds."
            ],
            [
                "PhoneCalls<br>| join duration on CallConnectionId<br>",
                "Putting things together."
            ],
            [
                "| extend propjson = parse_json(Properties)<br>",
                "As this is a json format we need to parse it as such. This is mostly a habit for me, sometimes you dont have to and can get the items you want directly, but sometimes you have to explicitly tell KQL that this should be treated as JSON. "
            ],
            [
                "| extend Origin = propjson.Origin, Destination=propjson.Destination, visibility = propjson.IsHidden, DisconnectedBy = propjson.Disconnectedby<br>",
                "Now we would like to get into the different values to consider going forward. It seems like a smart move to hide your tracks by calling with hidden visibility. Also, another assumption i made was that the phishers must have made their target upset which could be indicated by looking deeper into the DisconnectedBy value. There are lots of ways to go from here, and I'm sure there are many ways that would lead to the same answer, but i decided to investigate if I could reveal them based on call duration."
            ],
            [
                "| project Origin, call_duration, Connect_Time<br>| summarize nums_of_calls = count() by , tostring(Origin)<br>| where Origin != \"\"<br>| order by nums_of_calls desc",
                "And indeed I could. Hidden between the meaning of life, the universe, and everything is your answer. This way of solving it would probably be more difficult if this was naturally created numbers and not fictional. Or perhaps the phishers played a prerecorded audio that lasted this long for each phonecall."
            ]
        ],
        "category": [
            "kustodetectiveagency2023",
            "adx",
            "let",
            "where",
            "project",
            "extend",
            "order by",
            "summarize",
            "count()",
            "dot notation",
            "parse_json()",
            "datetime_diff()",
            "join"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2023 - Case 3 - Return Stolen Cars",
        "code": [
            [
                "CarsTraffic<br>",
                "Fetching the table..."
            ],
            [
                "| where VIN in (StolenCars)<br>",
                "Let's focus on the known stolen cars."
            ],
            [
                "| where VIN in (StolenCars)<br>",
                "Let's make the assumption that the cars were stolen, license plate was changed, and the car changed to did not move. With this line of KQL we are minimizing the data to only look for the stolen cars. 20 listed in the StolenCars set we were provided. This indicates there might be more."
            ],
            [
                "// Assuming the last location of vehicles stolen is the last location they were sighted (arg_max)<br>| summarize arg_max(Timestamp, Ave, Street) by VIN<br>",
                "Next up we are looking at where they stayed the last time they were observed. We do so with the arg_max function that. We want to retrive the last time of each unique combination for whatever columns we provide next. We will be looking at Ave and Street. And we are summarizing that on VIN. Remember this from last years KDA?"
            ],
            [
                "| join CarsTraffic on Ave, Street<br>",
                "After minimizing data, we will now maximize it based on our result. We now know where every stolen car were last seen. It also seems that we can draw a conclusion on knowing that they were stolen from pretty much the same areas. 2 different areas are repeating themselves. Now, we are joining that finding back on the full dataset to see all the cars that have been on these locations."
            ],
            [
                "// Where they are not the same - in other words, changed license plates<br>| where VIN != VIN1<br>",
                "... and we know that they changed the license, so we can easily remove those entries where the VINs are equal to each others."
            ],
            [
                "| where Timestamp1 between (Timestamp .. 2m)<br>",
                "Lets also assume that they did things pretty quick. One of the hints mentions a few minutes. And remember that the column names you don't set a different name for will be iterated like here. Now we are looking at Timestamp1 (the last table join) to be happening between when the car got parked and 2 minutes ahead. That's quick huh? Actually for the solution it works all the way up till 9 minutes for the top most result."
            ],
            [
                "| project VIN1<br>",
                "We only need the cars from now on. To reiterate, we are now with a set of cars that has the relation to the stolen cars in that they left the parking lot within 2 minutes of the stolen cars parking."
            ],
            [
                "| join CarsTraffic on $left.VIN1 == $right.VIN<br>",
                "Doing a join to focus only on those cars of interest."
            ],
            [
                "| summarize arg_max(Timestamp, Ave, Street) by VIN<br>",
                "Now we want to see where those cars were last spotted. Same technique as previous and last years KDA."
            ],
            [
                "| summarize count() by Ave, Street<br>// Remove locations where cars were stolen from<br>| where Ave != 223 and Street != 86 and Ave != 122 and Street != 251<br>",
                "Let's count them up and remove the location of where they were stolen from."
            ],
            [
                "| join (CarsTraffic<br>    | summarize arg_max(Timestamp, Ave, Street) by VIN<br>) on Ave, Street<br>",
                "Next up we want to highlight all the cars' last location and join that on our current set of interesting location."
            ],
            [
                "| summarize count() by Ave, Street",
                "Let's count it up and your answer is the one with most counts. top 1 also reveals that. You can also count how many cars were stolen based on the finding: <pre> CarsTraffic <br>| summarize arg_max(Timestamp, Ave, Street) by VIN <br>| where Ave == 156 and Street == 81 <br>| count</pre> "
            ]
        ],
        "category": [
            "kustodetectiveagency2023",
            "adx",
            "summarize",
            "count()",
            "arg_max()",
            "project",
            "where",
            "join",
            "in"
        ],
        "author": "bittib010"
    },
    {
        "name": "Kusto Detective Agency 2023 - Case 4 - Triple Trouble",
        "code": [
            [
                "let time_gap = 1d;<br>",
                "Define a variable 'time_gap' set to 1 day. We are informed on the training section to use the series_decompose_anomalies() function, or at least, they hint towards this being the function to use. Based on this knowledge a solution jumps right into my thought on querying on the average amount of data. The information we have received also makes me believe that we are looking at anomalies in data, anomalies that may indeed be very different in relation to normal data flow, suggesting a probable hit with the \"top 1\" at the end of the query. NB! This query will run for 2.5 minute."],
            [
                "NetworkMetrics<br>",
                "Selecting the 'NetworkMetrics' table"
            ],
            [
                "| where NewConnections > 0<br>",
                "Filtering the data where 'NewConnections' are greater than 0. Considering these are cyber attacks, looking for new connections was an easy way to reduce the amount of data to look through. I tried a few different queries beginning this quest where I never got the answer of my query. The dataset was too large for them to be run before timing out. If this ever happens to you, look for ways to reduce the amount of data."
            ],
            [
                "| evaluate ipv4_lookup",
                "This is the tabular function that is being invoked making us able to add the IP to a IP CIDR block to find it's owner. It matches a list of IPv4 addresses against a list of CIDR blocks."
            ],
            [
                "(IpInfo, ClientIP, IpCidr)<br>",
                "These are the arguments to the ipv4_lookup function. The function matches 'ClientIP' against 'IpCidr' in the 'IpInfo' table. Doing this, we are able to match an IP address to the company owner."
            ],
            [
                "| make-series BytesSent=avg(BytesSent) on Timestamp step time_gap by Info<br>",
                "Creating a time series of average 'BytesSent' on 'Timestamp' stepped by 'time_gap' (which is set to 1 day) and grouped by 'Info'. I decided on choosing average here as I initially though that would make the most sense to catch anomalies on. In hindsight on reading others' writeups, sum() can also be used."
            ],
            [
                "| extend (BytesSentAnomaly, BytesSentAnomalyScore) = ",
                "These are the new columns being added to the table. Putting them in braces makes it a list, as we only assign one variable a new value before the equal sign (=), putting them before the equal sign inside braces makes us able to assign more variables at the same time."
            ],
            [
                "series_decompose_anomalies(BytesSent)<br>",
                "This function decomposes the time series into its trend and residual components, and calculates anomaly scores. It returns a tuple that's assigned to the new columns."
            ],
            [
                "| mv-expand BytesSentAnomalyScore to typeof(double)<br>",
                "Expanding the list in 'BytesSentAnomalyScore' into multiple rows of type double"
            ],
            [
                "| top 1 by BytesSentAnomalyScore <br>",
                "Selecting the top 1 row by 'BytesSentAnomalyScore'"
            ],
            [
                "| render anomalychart with(anomalycolumns=BytesSentAnomaly, BytesSentAnomalyScore)",
                "Rendering an anomaly chart with 'BytesSentAnomaly' and 'BytesSentAnomalyScore' as anomaly columns. This visualization helps in identifying the anomalies in the data by plotting the data points (with their scores) that are considered anomalous"
            ]
        ],
        "author": "bittib010",
        "category": [
            "let",
            "where",
            "evaluate",
            "ipv4_lookup()",
            "make-series()",
            "extend",
            "series_decompose_anomalies()",
            "mv-expand",
            "top",
            "render",
            "anomalychart",
            "step"
        ]
    },    
    {
        "name": "Uncovering anomalies in time-series data - Changes over time <a href=\"https://www.opsman.co.za/uncovering-anomalies-in-time-series-data-with-kusto-query-language-kql/\"> Original Post</a>",
        "code": [
            [
                "let window = 7d;<br>",
                "Setting a loockback window as a variable is always a good start to make it easier to change and spot where to do the change."
            ],
            [
                "Perf<br>",
                "Fetching the table..."
            ],
            [
                "| where ObjectName == \"Processor\" and CounterName == \"% Processor Time\"<br>",
                ""
            ],
            [
                "| where TimeGenerated > ago(window)<br>",
                ""
            ],
            [
                "| summarize avg(CounterValue) by Computer, TimeGenerated = startofday(TimeGenerated)<br>",
                ""
            ],
            [
                "| join (<br>",
                ""
            ],
            [
                "Perf<br>",
                ""
            ],
            [
                "| where ObjectName == \"Processor\" and CounterName == \"% Processor Time\"<br>",
                ""
            ],
            [
                "| where TimeGenerated > ago(window)<br>",
                ""
            ],
            [
                "| summarize arg_min(TimeGenerated, CounterValue) by Computer, TimeGenerated = startofday(TimeGenerated)<br>",
                ""
            ],
            [
                "| where TimeGenerated < TimeGenerated<br>",
                ""
            ],
            [
                "| project Computer, TimeGenerated, CounterValue<br>",
                ""
            ],
            [
                ") on Computer, TimeGenerated<br>",
                ""
            ],
            [
                "| extend diff = avg_CounterValue - CounterValue<br>",
                ""
            ],
            [
                "| where abs(diff) > 10<br>",
                ""
            ]
        ],
        "category": [
            ""
        ],
        "author": ""
    },
    {
        "name": "Map UPN to UDN via watchlist",
        "code": [
            [
                "let vips = _GetWatchlist('VIPs') // VIPS consists of UPNs",
                "Lets create a variable that holds all the watchlist data..."
            ],
            [
                "| summarize make_list(Description);",
                "... and then reduce it to only the Description column - which is the column for the data we want: user@domain.com."
            ],
            [
                "let mapped_vips = SigninLogs // Map UPNs to UserDisplayName<br>| where UserPrincipalName in (vips)<br>",
                "Next up we want to fetch all the UserPrincipalName's that also exists inside the watchlist variable we created."
            ],
            [
                "| distinct UserDisplayName",
                "To avoid duplicates, we will be using distinct. Probably not necessary in many cases - consider this optional."
            ],
            [
                "| summarize UDN = make_list(UserDisplayName);",
                "Summarize to create a list is pretty handy, but also not necessary, depending on your end goal this might be handy or hard to read."
            ]
        ],
        "category": [
            "sentinel",
            "_GetWatchlist()",
            "let",
            "summarize",
            "make_list()",
            "distinct"
        ],
        "author": "bittib010"
    },
    {
        "name": "union with kind=inner",
        "code": [
            [
                "SigninLogs<br>",
                "Fetch the data..."
            ],
            [
                "| union kind=inner AADNonInteractiveUserSignInLogs<br>",
                "According to MS docs: \"inner causes the result to have the subset of columns that are common to all of the input tables.\" By doing any filtering on the first table before this will not work on the joined table, if you want to filter out both, you need to union them first. union default to outer, therefore inner has to be explicitly set. Also note that a lot of cells will have the value of 'none', MS states that \"Cells that aren't defined by an input row are set to null.\""
            ],
            [
                "| where UserPrincipalName contains \"John\"",
                "Start filtering to find all you need in both tables. Keep in mind that columns from the right (second) table that do not exist in the left table (first) will not show."
            ]
        ],
        "author": "BenAarvik",
        "category": [
            "union",
            "with",
            "kind",
            "inner",
            "where",
            "contains"
        ]
    },
    {
        "name": "Permutation - combine a day range with all table-names from a given time period.",
        "code": [
            [
                "let days = ",
                "Defining a new variable 'days'"
            ],
            [
                "range day_range ",
                "Creating a range named 'day_range'"
            ],
            [
                "from ago(7d) ",
                "Starting the range from 7 days ago"
            ],
            [
                "to now() ",
                "Ending the range at the current time"
            ],
            [
                "step 1d<br>",
                "Setting the interval of the range to 1 day"
            ],
            [
                "| summarize make_list(day_range);<br>",
                "Aggregate the range of dates into a list"
            ],
            [
                "search *",
                "Search all data"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "where TimeGenerated >= ago(50d)",
                "Filtering for data generated within the last 50 days"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "distinct $table",
                "Get a distinct list of table names from the search results"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "extend p = toscalar(days)",
                "Extend the result set with a new column 'p', using the 'test' variable values"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "mv-expand p",
                "Create new rows for each value in the 'p' column"
            ]
        ],
        "author": "bittib010",
        "category": [
            "summarize",
            "mv-expand",
            "extend",
            "toscalar()",
            "where",
            "search",
            "step",
            "to now",
            "let",
            "range"
        ]
    },
    {
        "name": "Count continuous data entry days in each table",
        "code": [
            [
                "let days= range day_range from ago(14d) to now() step 1d<br>",
                "Defining a variable 'days' as a date range from 14 days ago to now, stepping in 1-day increments"
            ],
            [
                "| summarize make_list(day_range);<br>",
                "Aggregate the range of dates into a list"
            ],
            [
                "let all_data = search *<br>",
                "Defining a variable 'all_data' as a search of all data"
            ],
            [
                "| where TimeGenerated >= ago(31d)<br>",
                "Filtering for data generated within the last 31 days"
            ],
            [
                "| summarize entries_this_day = count() by bin(TimeGenerated, 1d), $table<br>",
                "Aggregating data to get a count of entries by day and table"
            ],
            [
                "| extend format_datetime(TimeGenerated, 'yyyy-MM-dd');<br>",
                "Formatting the 'TimeGenerated' field to 'yyyy-MM-dd'"
            ],
            [
                "search *",
                "Searching all data"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "where TimeGenerated >= ago(50d)",
                "Filtering for data generated within the last 50 days"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "distinct $table",
                "Get a distinct list of table names from the search results"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "extend generic_day_range = toscalar(days)",
                "Extend the result set with a new column 'generic_day_range', using the 'days' variable values"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "mv-expand generic_day_range",
                "Create new rows for each value in the 'generic_day_range' column"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "extend format_datetime(todatetime(generic_day_range), 'yyyy-MM-dd')",
                "Convert 'generic_day_range' to datetime and format it to 'yyyy-MM-dd'"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "lookup all_data on $table, $left.generic_day_range == $right.TimeGenerated",
                "Join the result set with 'all_data' based on table name and date"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "order by $table, generic_day_range asc",
                "Order the result set by table name and 'generic_day_range' in ascending order"
            ],
            [
                "<br>| ",
                "pipe current data selection further into the next part of the query"
            ],
            [
                "extend days_in_row_per_table = row_number(1, (not(entries_this_day == '') or prev($table) != $table))",
                "Add a new column 'days_in_row_per_table' that counts the rows for each table"
            ]
        ],
        "author": "bittib010",
        "category": [
            "let",
            "range",
            "summarize",
            "make_list()",
            "search",
            "where",
            "ago()",
            "bin()",
            "extend",
            "format_datetime()",
            "distinct",
            "toscalar()",
            "mv-expand",
            "lookup",
            "order by",
            "row_number()",
            "prev()",
            "not()",
            "sentinel"
        ]
    }
]